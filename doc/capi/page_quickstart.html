<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Steam Audio API: Quick Start: Rendering 3D Audio</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Steam Audio API
   &#160;<span id="projectnumber">2.0-beta.18</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',false,false,'search.php','Search');
});
</script>
<div id="main-nav"></div>
<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="index.html">index</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Quick Start: Rendering 3D Audio </div>  </div>
</div><!--header-->
<div class="contents">
<div class="toc"><h3>Table of Contents</h3>
<ul><li class="level1"><a href="#quickstart_exploring">The Sample Application</a><ul><li class="level2"><a href="#quickstart_exploring_loading">Loading Input Audio</a></li>
<li class="level2"><a href="#quickstart_exploring_init">Steam Audio Initialization</a></li>
<li class="level2"><a href="#quickstart_exploring_renderer">Binaural Renderer</a></li>
<li class="level2"><a href="#quickstart_exploring_format">Audio Formats</a></li>
<li class="level2"><a href="#quickstart_exploring_effect">Binaural Effect</a></li>
<li class="level2"><a href="#quickstart_exploring_buffer">Audio Buffers</a></li>
<li class="level2"><a href="#quickstart_exploring_apply">Main Processing Loop</a></li>
<li class="level2"><a href="#quickstart_exploring_destroy">Cleanup</a></li>
</ul>
</li>
<li class="level1"><a href="#quickstart_complete">Complete Code Listing</a></li>
</ul>
</div>
<div class="textblock"><p>This page provides an example of using Steam Audio for applying HRTF-based 3D audio to mono (single-channel) audio data.</p>
<p>To avoid complicating this example with code related to graphical rendering, audio engines, and codecs, this example is a C++ command-line tool that loads audio data from a file, applies 3D audio effects to it, and saves it to another file.</p>
<h1><a class="anchor" id="quickstart_exploring"></a>
The Sample Application</h1>
<p>Before using any Steam Audio functionality, we must include the necessary headers:</p>
<div class="fragment"><div class="line"><span class="preprocessor">#include &lt;phonon.h&gt;</span></div></div><!-- fragment --><p>The rest of this section describes each step that must be carried out for this program to load audio data, initialize Steam Audio, and use Steam Audio for 3D audio processing.</p>
<h2><a class="anchor" id="quickstart_exploring_loading"></a>
Loading Input Audio</h2>
<p>To avoid dealing with codecs and audio file loaders in this sample application, we assume that the input audio data is stored in a "raw" audio file. This file contains nothing but the contents of the input audio signal, stored in PCM format with 32-bit single-precision floating point samples. You can use free tools like <a href="http://www.audacityteam.org/">Audacity</a> to create and listen to such audio files.</p>
<div class="fragment"><div class="line">std::vector&lt;float&gt; inputaudio = load_input_audio(<span class="stringliteral">&quot;inputaudio.raw&quot;</span>);</div></div><!-- fragment --><p>This loads the audio data from the file <code>inputaudio.raw</code> and stores it in an <code>std::vector&lt;float&gt;</code>. For more details on how the <code>load_input_audio</code> function is implemented, see the complete code listing at the end of this page.</p>
<h2><a class="anchor" id="quickstart_exploring_init"></a>
Steam Audio Initialization</h2>
<p>The first step in initializing Steam Audio is specifying a context object. This is mainly intended for applications that need to override Steam Audio's logging system (to display log messages in an editor window, for example) or memory allocation system (to use a custom allocator, for example). Since we don't need any of this functionality, we can just set everything to <code>nullptr</code>:</p>
<div class="fragment"><div class="line"><a class="code" href="group__types.html#ga08dc6de588508173d4396acfd3e08204" title="An opaque handle to a Phonon API object. ">IPLhandle</a> context{<span class="keyword">nullptr</span>};</div><div class="line"><a class="code" href="group__context.html#ga8234c987a977fb67fd54074cf77639bc" title="Creates a Context object. ">iplCreateContext</a>(<span class="keyword">nullptr</span>, <span class="keyword">nullptr</span>, <span class="keyword">nullptr</span>, &amp;context);</div></div><!-- fragment --><p>The next step is to specify the <em>sampling rate</em> and <em>frame size</em> of our audio processing code. We assume that input and output audio is sampled at 44.1 kHz, and that audio is processed in frames of 1024 samples:</p>
<div class="fragment"><div class="line"><span class="keyword">auto</span> <span class="keyword">const</span> samplingrate = 44100;</div><div class="line"><span class="keyword">auto</span> <span class="keyword">const</span> framesize    = 1024;</div><div class="line"><a class="code" href="struct_i_p_l_rendering_settings.html" title="Describes various properties of the audio processing pipeline. ">IPLRenderingSettings</a> settings{ samplingrate, framesize };</div></div><!-- fragment --><p>See <a class="el" href="struct_i_p_l_rendering_settings.html">IPLRenderingSettings</a> for details.</p>
<h2><a class="anchor" id="quickstart_exploring_renderer"></a>
Binaural Renderer</h2>
<p>The next step is to create a <a class="el" href="group__binauralrenderer.html">Binaural Renderer</a> object:</p>
<div class="fragment"><div class="line"><a class="code" href="group__types.html#ga08dc6de588508173d4396acfd3e08204" title="An opaque handle to a Phonon API object. ">IPLhandle</a> renderer{ <span class="keyword">nullptr</span> };</div><div class="line"><a class="code" href="struct_i_p_l_hrtf_params.html" title="Parameters used to describe the HRTF database you want to use when creating a Binaural Renderer objec...">IPLHrtfParams</a> hrtfParams{ <a class="code" href="group__binauralrenderer.html#ggac8a67c4db14832ec5fc923dc5cdc41c3a5ecfd401d1000e3fdcf58e5f96d50827" title="The built-in HRTF database. ">IPL_HRTFDATABASETYPE_DEFAULT</a>, <span class="keyword">nullptr</span>, 0, <span class="keyword">nullptr</span>, <span class="keyword">nullptr</span>, <span class="keyword">nullptr</span> };</div><div class="line"><a class="code" href="group__binauralrenderer.html#ga214f23f4a3952891a0881279083a370a" title="Creates a Binaural Renderer object. ">iplCreateBinauralRenderer</a>(context, settings, hrtfParams, &amp;renderer);</div></div><!-- fragment --><p>The <code>IPLhandle</code> type is used for opaque handles to various objects created using the Steam Audio API. The Binaural Renderer object is must not be destroyed until all 3D audio processing is complete. See <a class="el" href="group__binauralrenderer.html#ga214f23f4a3952891a0881279083a370a">iplCreateBinauralRenderer</a> for details. The <code><a class="el" href="struct_i_p_l_hrtf_params.html" title="Parameters used to describe the HRTF database you want to use when creating a Binaural Renderer objec...">IPLHrtfParams</a></code> structure lets you specify custom HRTF data; we will not be using this feature in this sample program, so we initialize it to default values.</p>
<h2><a class="anchor" id="quickstart_exploring_format"></a>
Audio Formats</h2>
<p>Next, we spell out the audio formats that we will be using for our input and output signals. The input is a single-channel mono file, whereas the output is a 2-channel stereo file, since it contains data that has been rendered using HRTF-based binaural rendering:</p>
<div class="fragment"><div class="line"><a class="code" href="struct_i_p_l_audio_format.html" title="The format of an audio buffer. ">IPLAudioFormat</a> mono;</div><div class="line">mono.<a class="code" href="struct_i_p_l_audio_format.html#a949d67e69189ea254a4b1d9f56494015" title="Indicates whether or not the audio should be interpreted as Ambisonics data. ">channelLayoutType</a>  = <a class="code" href="group__audiobuffer.html#gga3a43755062bd69159e9a75c2b7b86cc3a8fbd8523a4546b58db704306bcbbacd4" title="Indicates that each channel of audio data is intended to be played back by a single speaker...">IPL_CHANNELLAYOUTTYPE_SPEAKERS</a>;</div><div class="line">mono.<a class="code" href="struct_i_p_l_audio_format.html#af53c12364e1881e2e63298ffcbadf0d0" title="Specifies the speaker configuration used for multi-channel, speaker-based audio data. ">channelLayout</a>      = <a class="code" href="group__audiobuffer.html#ggaf6effca02547c6553609d1db3981217cad0b6787987fd287e1a4adf35831fec1c" title="A single speaker, typically in front of the user. ">IPL_CHANNELLAYOUT_MONO</a>;</div><div class="line">mono.<a class="code" href="struct_i_p_l_audio_format.html#a261af909acc98b0f1bde74743a1f08ec" title="Whether the audio data is interleaved or deinterleaved. ">channelOrder</a>       = <a class="code" href="group__audiobuffer.html#ggab3640560f40603c781e745296be1bb06a796b7770747ee3098f9e1a5cb4b5aaa4" title="Sample values for each channel are stored one after another, followed by the next set of sample value...">IPL_CHANNELORDER_INTERLEAVED</a>;</div><div class="line"></div><div class="line"><a class="code" href="struct_i_p_l_audio_format.html" title="The format of an audio buffer. ">IPLAudioFormat</a> stereo;</div><div class="line">stereo.<a class="code" href="struct_i_p_l_audio_format.html#a949d67e69189ea254a4b1d9f56494015" title="Indicates whether or not the audio should be interpreted as Ambisonics data. ">channelLayoutType</a>  = <a class="code" href="group__audiobuffer.html#gga3a43755062bd69159e9a75c2b7b86cc3a8fbd8523a4546b58db704306bcbbacd4" title="Indicates that each channel of audio data is intended to be played back by a single speaker...">IPL_CHANNELLAYOUTTYPE_SPEAKERS</a>;</div><div class="line">stereo.<a class="code" href="struct_i_p_l_audio_format.html#af53c12364e1881e2e63298ffcbadf0d0" title="Specifies the speaker configuration used for multi-channel, speaker-based audio data. ">channelLayout</a>      = <a class="code" href="group__audiobuffer.html#ggaf6effca02547c6553609d1db3981217ca64e55dbca035dac9ee468eda88e5c589" title="A pair of speakers, one to the left of the user, and one to the right. ">IPL_CHANNELLAYOUT_STEREO</a>;</div><div class="line">stereo.<a class="code" href="struct_i_p_l_audio_format.html#a261af909acc98b0f1bde74743a1f08ec" title="Whether the audio data is interleaved or deinterleaved. ">channelOrder</a>       = <a class="code" href="group__audiobuffer.html#ggab3640560f40603c781e745296be1bb06a796b7770747ee3098f9e1a5cb4b5aaa4" title="Sample values for each channel are stored one after another, followed by the next set of sample value...">IPL_CHANNELORDER_INTERLEAVED</a>;</div></div><!-- fragment --><p>Both the input and output formats are specified as <em>interleaved</em>: this means that data for all channels for the first sample is stored contiguously, followed by data for all channels for the second sample, and so on. See <a class="el" href="struct_i_p_l_audio_format.html">IPLAudioFormat</a> for details.</p>
<h2><a class="anchor" id="quickstart_exploring_effect"></a>
Binaural Effect</h2>
<p>Next, we create an <a class="el" href="group__binauraleffect.html">Object-Based Binaural Effect</a> object, which is used to apply 3D audio effects to a specific, single source:</p>
<div class="fragment"><div class="line"><a class="code" href="group__types.html#ga08dc6de588508173d4396acfd3e08204" title="An opaque handle to a Phonon API object. ">IPLhandle</a> effect{ <span class="keyword">nullptr</span> };</div><div class="line"><a class="code" href="group__binauraleffect.html#ga4a9fdcacc0818d11b631271e2db6cb4c" title="Creates an Object-Based Binaural Effect object. ">iplCreateBinauralEffect</a>(renderer, mono, stereo, &amp;effect);</div></div><!-- fragment --><p>Here, we specify that the input to the Effect object will be mono, and the output will be stereo. See <a class="el" href="group__binauraleffect.html#ga4a9fdcacc0818d11b631271e2db6cb4c">iplCreateBinauralEffect</a> for details.</p>
<h2><a class="anchor" id="quickstart_exploring_buffer"></a>
Audio Buffers</h2>
<p>Next, we define <a class="el" href="struct_i_p_l_audio_buffer.html">IPLAudioBuffer</a> objects that represent the input and output audio buffers. First, the input buffer, which represents one frame of input data:</p>
<div class="fragment"><div class="line"><a class="code" href="struct_i_p_l_audio_buffer.html" title="A buffer containing audio data. ">IPLAudioBuffer</a> inbuffer{ mono, framesize, inputaudio.data() };</div></div><!-- fragment --><p>The input buffer points to the start of the data loaded from the input file. This way, the first input audio frame is set to the first 1024 samples of the input data.</p>
<p>Second, we specify the output buffer:</p>
<div class="fragment"><div class="line">std::vector&lt;float&gt; outputaudioframe(2 * framesize);</div><div class="line"><a class="code" href="struct_i_p_l_audio_buffer.html" title="A buffer containing audio data. ">IPLAudioBuffer</a> outbuffer{ stereo, framesize, outputaudioframe.data() };</div></div><!-- fragment --><p>We first create a <code>std::vector&lt;float&gt;</code> that can hold 1024 samples of stereo data, then create an <a class="el" href="struct_i_p_l_audio_buffer.html" title="A buffer containing audio data. ">IPLAudioBuffer</a> object that points to the data contained in the <code>std::vector&lt;float&gt;</code>.</p>
<h2><a class="anchor" id="quickstart_exploring_apply"></a>
Main Processing Loop</h2>
<p>The main processing loop applies 3D audio effects to the input audio one frame at a time, accumulating the results in an output buffer that will be written to disk at the end of the loop. First, we create a <code>std::vector&lt;float&gt;</code> to store the final output data:</p>
<div class="fragment"><div class="line">std::vector&lt;float&gt; outputaudio;</div></div><!-- fragment --><p>We then calculate the number of audio frames that we will be processing:</p>
<div class="fragment"><div class="line"><span class="keyword">auto</span> numframes = <span class="keyword">static_cast&lt;</span><span class="keywordtype">int</span><span class="keyword">&gt;</span>(inputaudio.size() / framesize);</div></div><!-- fragment --><p>Finally, we run the processing loop <code>numframes</code> times:</p>
<div class="fragment"><div class="line"><span class="keywordflow">for</span> (<span class="keyword">auto</span> i = 0; i &lt; numframes; ++i)</div><div class="line">{</div><div class="line">    <a class="code" href="group__binauraleffect.html#gac5a700d7bc764d0d12553e07f6d7beaf" title="Applies HRTF-based binaural rendering to a buffer of audio data. ">iplApplyBinauralEffect</a>(effect, inbuffer, <a class="code" href="struct_i_p_l_vector3.html" title="A point or vector in 3D space. ">IPLVector3</a>{ 1.0f, 1.0f, 1.0f }, <a class="code" href="group__binauraleffect.html#gga9058672cce5fa7c068ff2e90bc98aa18a4ea0fb2ab0361b8c7636e98f3564c683" title="Nearest-neighbor filtering, i.e., no interpolation. ">IPL_HRTFINTERPOLATION_NEAREST</a>, outbuffer);</div><div class="line">    std::copy(std::begin(outputaudioframe), std::end(outputaudioframe), std::back_inserter(outputaudio));</div><div class="line">    inbuffer.interleavedBuffer += framesize;</div><div class="line">}</div></div><!-- fragment --><p>The loop consists of three steps:</p>
<ol type="1">
<li>We call <a class="el" href="group__binauraleffect.html#gac5a700d7bc764d0d12553e07f6d7beaf">iplApplyBinauralEffect</a> to tell Steam Audio to render the input buffer using HRTF-based binaural rendering. We use a fixed direction from the listener to the source, (1, 1, 1): the source is above, behind, and to the right of the listener. Since the source does not move relative to the listener, we use nearest-neighbor filtering for maximum performance.</li>
<li>We append the output frame to <code>outputaudio</code>, the buffer that will be written to disk.</li>
<li>We advance the input audio by a single frame, by advancing the input buffer's <code>interleavedBuffer</code> pointer by 1024 samples.</li>
</ol>
<h2><a class="anchor" id="quickstart_exploring_destroy"></a>
Cleanup</h2>
<p>Once we've finished using Steam Audio, we must destroy the objects created using the Steam Audio API, and perform last-minute cleanup:</p>
<div class="fragment"><div class="line"><a class="code" href="group__binauraleffect.html#gab224f46a28b32933b3cfa0d7d398b540" title="Destroys an Object-Based Binaural Effect object. ">iplDestroyBinauralEffect</a>(&amp;effect);</div><div class="line"><a class="code" href="group__binauralrenderer.html#ga09c91f4334dd31236a54e352353d6c09" title="Destroys a Binaural Renderer object. ">iplDestroyBinauralRenderer</a>(&amp;renderer);</div><div class="line"><a class="code" href="group__context.html#ga63e5b1ddfade316636d195bc5ddd6c31" title="Destroys a Context object. ">iplDestroyContext</a>(&amp;context);</div><div class="line"><a class="code" href="group__context.html#gad4db22c97f5ccef241a39da4296550aa" title="Performs last-minute cleanup and finalization. ">iplCleanup</a>();</div></div><!-- fragment --><p>The last step is to write the processed audio to disk:</p>
<div class="fragment"><div class="line">save_output_audio(<span class="stringliteral">&quot;outputaudio.raw&quot;</span>, outputaudio);</div></div><!-- fragment --><p>For details on how <code>save_output_audio</code> is implemented, see the complete code listing below.</p>
<h1><a class="anchor" id="quickstart_complete"></a>
Complete Code Listing</h1>
<p>A complete code listing of the sample application follows. See <a class="el" href="page_compiling.html">Compiling and Linking with Steam Audio</a> for more information on how to compile and run this code in your development environment.</p>
<div class="fragment"><div class="line"><span class="preprocessor">#include &lt;algorithm&gt;</span></div><div class="line"><span class="preprocessor">#include &lt;fstream&gt;</span></div><div class="line"><span class="preprocessor">#include &lt;iterator&gt;</span></div><div class="line"><span class="preprocessor">#include &lt;vector&gt;</span></div><div class="line"></div><div class="line"><span class="preprocessor">#include &lt;phonon.h&gt;</span></div><div class="line"></div><div class="line">std::vector&lt;float&gt; load_input_audio(<span class="keyword">const</span> std::string filename)</div><div class="line">{</div><div class="line">    std::ifstream file(filename.c_str(), std::ios::binary);</div><div class="line"></div><div class="line">    file.seekg(0, std::ios::end);</div><div class="line">    <span class="keyword">auto</span> filesize = file.tellg();</div><div class="line">    <span class="keyword">auto</span> numsamples = <span class="keyword">static_cast&lt;</span><span class="keywordtype">int</span><span class="keyword">&gt;</span>(filesize / <span class="keyword">sizeof</span>(float));</div><div class="line"></div><div class="line">    std::vector&lt;float&gt; inputaudio(numsamples);</div><div class="line">    file.seekg(0, std::ios::beg);</div><div class="line">    file.read(reinterpret_cast&lt;char*&gt;(inputaudio.data()), filesize);</div><div class="line"></div><div class="line">    <span class="keywordflow">return</span> inputaudio;</div><div class="line">}</div><div class="line"></div><div class="line"><span class="keywordtype">void</span> save_output_audio(<span class="keyword">const</span> std::string filename, std::vector&lt;float&gt; outputaudio)</div><div class="line">{</div><div class="line">    std::ofstream file(filename.c_str(), std::ios::binary);</div><div class="line">    file.write(reinterpret_cast&lt;char*&gt;(outputaudio.data()), outputaudio.size() * <span class="keyword">sizeof</span>(float));</div><div class="line">}</div><div class="line"></div><div class="line"><span class="keywordtype">int</span> main(<span class="keywordtype">int</span> argc, <span class="keywordtype">char</span>** argv)</div><div class="line">{</div><div class="line">    <span class="keyword">auto</span> inputaudio = load_input_audio(<span class="stringliteral">&quot;inputaudio.raw&quot;</span>);</div><div class="line"></div><div class="line">    <a class="code" href="group__types.html#ga08dc6de588508173d4396acfd3e08204" title="An opaque handle to a Phonon API object. ">IPLhandle</a> context{<span class="keyword">nullptr</span>};</div><div class="line">    <a class="code" href="group__context.html#ga8234c987a977fb67fd54074cf77639bc" title="Creates a Context object. ">iplCreateContext</a>(<span class="keyword">nullptr</span>, <span class="keyword">nullptr</span>, <span class="keyword">nullptr</span>, &amp;context);</div><div class="line"></div><div class="line">    <span class="keyword">auto</span> <span class="keyword">const</span> samplingrate = 44100;</div><div class="line">    <span class="keyword">auto</span> <span class="keyword">const</span> framesize    = 1024;</div><div class="line">    <a class="code" href="struct_i_p_l_rendering_settings.html" title="Describes various properties of the audio processing pipeline. ">IPLRenderingSettings</a> settings{ samplingrate, framesize };</div><div class="line"></div><div class="line">    <a class="code" href="group__types.html#ga08dc6de588508173d4396acfd3e08204" title="An opaque handle to a Phonon API object. ">IPLhandle</a> renderer{ <span class="keyword">nullptr</span> };</div><div class="line">    <a class="code" href="struct_i_p_l_hrtf_params.html" title="Parameters used to describe the HRTF database you want to use when creating a Binaural Renderer objec...">IPLHrtfParams</a> hrtfParams{ <a class="code" href="group__binauralrenderer.html#ggac8a67c4db14832ec5fc923dc5cdc41c3a5ecfd401d1000e3fdcf58e5f96d50827" title="The built-in HRTF database. ">IPL_HRTFDATABASETYPE_DEFAULT</a>, <span class="keyword">nullptr</span>, 0, <span class="keyword">nullptr</span>, <span class="keyword">nullptr</span>, <span class="keyword">nullptr</span> };</div><div class="line">    <a class="code" href="group__binauralrenderer.html#ga214f23f4a3952891a0881279083a370a" title="Creates a Binaural Renderer object. ">iplCreateBinauralRenderer</a>(context, settings, hrtfParams, &amp;renderer);</div><div class="line"></div><div class="line">    <a class="code" href="struct_i_p_l_audio_format.html" title="The format of an audio buffer. ">IPLAudioFormat</a> mono;</div><div class="line">    mono.<a class="code" href="struct_i_p_l_audio_format.html#a949d67e69189ea254a4b1d9f56494015" title="Indicates whether or not the audio should be interpreted as Ambisonics data. ">channelLayoutType</a>  = <a class="code" href="group__audiobuffer.html#gga3a43755062bd69159e9a75c2b7b86cc3a8fbd8523a4546b58db704306bcbbacd4" title="Indicates that each channel of audio data is intended to be played back by a single speaker...">IPL_CHANNELLAYOUTTYPE_SPEAKERS</a>;</div><div class="line">    mono.<a class="code" href="struct_i_p_l_audio_format.html#af53c12364e1881e2e63298ffcbadf0d0" title="Specifies the speaker configuration used for multi-channel, speaker-based audio data. ">channelLayout</a>      = <a class="code" href="group__audiobuffer.html#ggaf6effca02547c6553609d1db3981217cad0b6787987fd287e1a4adf35831fec1c" title="A single speaker, typically in front of the user. ">IPL_CHANNELLAYOUT_MONO</a>;</div><div class="line">    mono.<a class="code" href="struct_i_p_l_audio_format.html#a261af909acc98b0f1bde74743a1f08ec" title="Whether the audio data is interleaved or deinterleaved. ">channelOrder</a>       = <a class="code" href="group__audiobuffer.html#ggab3640560f40603c781e745296be1bb06a796b7770747ee3098f9e1a5cb4b5aaa4" title="Sample values for each channel are stored one after another, followed by the next set of sample value...">IPL_CHANNELORDER_INTERLEAVED</a>;</div><div class="line"></div><div class="line">    <a class="code" href="struct_i_p_l_audio_format.html" title="The format of an audio buffer. ">IPLAudioFormat</a> stereo;</div><div class="line">    stereo.<a class="code" href="struct_i_p_l_audio_format.html#a949d67e69189ea254a4b1d9f56494015" title="Indicates whether or not the audio should be interpreted as Ambisonics data. ">channelLayoutType</a>  = <a class="code" href="group__audiobuffer.html#gga3a43755062bd69159e9a75c2b7b86cc3a8fbd8523a4546b58db704306bcbbacd4" title="Indicates that each channel of audio data is intended to be played back by a single speaker...">IPL_CHANNELLAYOUTTYPE_SPEAKERS</a>;</div><div class="line">    stereo.<a class="code" href="struct_i_p_l_audio_format.html#af53c12364e1881e2e63298ffcbadf0d0" title="Specifies the speaker configuration used for multi-channel, speaker-based audio data. ">channelLayout</a>      = <a class="code" href="group__audiobuffer.html#ggaf6effca02547c6553609d1db3981217ca64e55dbca035dac9ee468eda88e5c589" title="A pair of speakers, one to the left of the user, and one to the right. ">IPL_CHANNELLAYOUT_STEREO</a>;</div><div class="line">    stereo.<a class="code" href="struct_i_p_l_audio_format.html#a261af909acc98b0f1bde74743a1f08ec" title="Whether the audio data is interleaved or deinterleaved. ">channelOrder</a>       = <a class="code" href="group__audiobuffer.html#ggab3640560f40603c781e745296be1bb06a796b7770747ee3098f9e1a5cb4b5aaa4" title="Sample values for each channel are stored one after another, followed by the next set of sample value...">IPL_CHANNELORDER_INTERLEAVED</a>;</div><div class="line"></div><div class="line">    <a class="code" href="group__types.html#ga08dc6de588508173d4396acfd3e08204" title="An opaque handle to a Phonon API object. ">IPLhandle</a> effect{ <span class="keyword">nullptr</span> };</div><div class="line">    <a class="code" href="group__binauraleffect.html#ga4a9fdcacc0818d11b631271e2db6cb4c" title="Creates an Object-Based Binaural Effect object. ">iplCreateBinauralEffect</a>(renderer, mono, stereo, &amp;effect);</div><div class="line"></div><div class="line">    std::vector&lt;float&gt; outputaudioframe(2 * framesize);</div><div class="line">    std::vector&lt;float&gt; outputaudio;</div><div class="line"></div><div class="line">    <a class="code" href="struct_i_p_l_audio_buffer.html" title="A buffer containing audio data. ">IPLAudioBuffer</a> inbuffer{ mono, framesize, inputaudio.data() };</div><div class="line">    <a class="code" href="struct_i_p_l_audio_buffer.html" title="A buffer containing audio data. ">IPLAudioBuffer</a> outbuffer{ stereo, framesize, outputaudioframe.data() };</div><div class="line"></div><div class="line">    <span class="keyword">auto</span> numframes = <span class="keyword">static_cast&lt;</span><span class="keywordtype">int</span><span class="keyword">&gt;</span>(inputaudio.size() / framesize);</div><div class="line">    <span class="keywordflow">for</span> (<span class="keyword">auto</span> i = 0; i &lt; numframes; ++i)</div><div class="line">    {</div><div class="line">        <a class="code" href="group__binauraleffect.html#gac5a700d7bc764d0d12553e07f6d7beaf" title="Applies HRTF-based binaural rendering to a buffer of audio data. ">iplApplyBinauralEffect</a>(effect, inbuffer, <a class="code" href="struct_i_p_l_vector3.html" title="A point or vector in 3D space. ">IPLVector3</a>{ 1.0f, 1.0f, 1.0f }, <a class="code" href="group__binauraleffect.html#gga9058672cce5fa7c068ff2e90bc98aa18a4ea0fb2ab0361b8c7636e98f3564c683" title="Nearest-neighbor filtering, i.e., no interpolation. ">IPL_HRTFINTERPOLATION_NEAREST</a>, outbuffer);</div><div class="line">        std::copy(std::begin(outputaudioframe), std::end(outputaudioframe), std::back_inserter(outputaudio));</div><div class="line">        inbuffer.interleavedBuffer += framesize;</div><div class="line">    }</div><div class="line"></div><div class="line">    <a class="code" href="group__binauraleffect.html#gab224f46a28b32933b3cfa0d7d398b540" title="Destroys an Object-Based Binaural Effect object. ">iplDestroyBinauralEffect</a>(&amp;effect);</div><div class="line">    <a class="code" href="group__binauralrenderer.html#ga09c91f4334dd31236a54e352353d6c09" title="Destroys a Binaural Renderer object. ">iplDestroyBinauralRenderer</a>(&amp;renderer);</div><div class="line">    <a class="code" href="group__context.html#ga63e5b1ddfade316636d195bc5ddd6c31" title="Destroys a Context object. ">iplDestroyContext</a>(&amp;context);</div><div class="line">    <a class="code" href="group__context.html#gad4db22c97f5ccef241a39da4296550aa" title="Performs last-minute cleanup and finalization. ">iplCleanup</a>();</div><div class="line"></div><div class="line">    save_output_audio(<span class="stringliteral">&quot;outputaudio.raw&quot;</span>, outputaudio);</div><div class="line">    <span class="keywordflow">return</span> 0;</div><div class="line">}</div></div><!-- fragment --> </div></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
